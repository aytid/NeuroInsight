# -*- coding: utf-8 -*-
"""main12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mRNR5gO03zkEmKb7MqQOi2Am3zLrVwZe
"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from scipy.io import arff
import tensorflow as tf
from tensorflow.keras import layers, models
import pandas as pd

data, meta = arff.loadarff('ip.arff')

import pandas as pd
df = pd.DataFrame(data)
df.head()

df.shape

df.info()

df.columns[1:]

df['class'].value_counts()

# Extract features and labels
X = df.iloc[:, :-1].values
y = df.iloc[:, -1]
y

y = df.iloc[:, -1].str.decode('utf-8').values

# Encode the labels using LabelEncoder
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
y_encoded

unique_labels = list(set(y))

# Print unique original labels and their corresponding encoded values
for original_label, encoded_label in zip(unique_labels, label_encoder.transform(unique_labels)):
    print(f"Original Label: {original_label}, Encoded Label: {encoded_label}")

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Encode the labels
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)

# Convert labels to one-hot encoding
num_classes = len(np.unique(y_train_encoded))
y_train_one_hot = np.eye(num_classes)[y_train_encoded]
y_train_one_hot

#displaying unique values
unique_encoded_values = set(y_train_encoded)
unique_one_hot_values = set(tuple(one_hot) for one_hot in y_train_one_hot)

print("Unique Encoded Values:", unique_encoded_values)
print("Unique One-Hot Values:", unique_one_hot_values)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense

# Reshape X_train for 1D CNN
X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)

# Define the 1D CNN model
model = Sequential()
model.add(Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)))
model.add(MaxPooling1D(2))
model.add(Conv1D(64, 3, activation='relu'))
model.add(MaxPooling1D(2))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train_reshaped, y_train_one_hot, epochs=10, batch_size=32, validation_split=0.2)
model.save('cnn.h5')

import matplotlib.pyplot as plt
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.tight_layout()
plt.show()

# Assuming y_train and y_test are numpy arrays or pandas Series
print("Contents of y_train:")
print(y_train)

print("\nContents of y_test:")
print(y_test)

X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)
# Make predictions
y_pred = model.predict(X_test_reshaped)
# Get the predicted classes
y_pred_classes = np.argmax(y_pred, axis=1)
# Print the predicted classes
print("Predicted Classes:", y_pred_classes)

from sklearn.metrics import accuracy_score
# Calculate accuracy for CNN
y_pred_cnn = model.predict(X_test_reshaped)
y_pred_classes_cnn = np.argmax(y_pred_cnn, axis=1)
accuracy_cnn = accuracy_score(y_test, y_pred_classes_cnn)
print(f"CNN Test Accuracy: {accuracy_cnn}")

# GRU Model
from tensorflow.keras.layers import GRU

model_gru = Sequential()
model_gru.add(GRU(50, activation='relu', input_shape=(X_train.shape[1], 1)))
model_gru.add(Dense(num_classes, activation='softmax'))
model_gru.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history_gru = model_gru.fit(X_train_reshaped, y_train_one_hot, epochs=10, batch_size=32, validation_split=0.2)
model.save('gru.h5')

# Plot accuracy and loss for GRU
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history_gru.history['accuracy'])
plt.plot(history_gru.history['val_accuracy'])
plt.title('GRU Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.subplot(1, 2, 2)
plt.plot(history_gru.history['loss'])
plt.plot(history_gru.history['val_loss'])
plt.title('GRU Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.tight_layout()
plt.show()

# Calculate accuracy for GRU
y_pred_gru = model_gru.predict(X_test_reshaped)
y_pred_classes_gru = np.argmax(y_pred_gru, axis=1)
accuracy_gru = accuracy_score(y_test, y_pred_classes_gru)
print(f"GRU Test Accuracy: {accuracy_gru}")

from keras.layers import Flatten, Dense

model_fcnn = Sequential()
model_fcnn.add(Flatten(input_shape=(X_train.shape[1], 1)))
model_fcnn.add(Dense(128, activation='relu'))
model_fcnn.add(Dense(64, activation='relu'))
model_fcnn.add(Dense(num_classes, activation='softmax'))
model_fcnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history_fcnn = model_fcnn.fit(X_train_reshaped, y_train_one_hot, epochs=10, batch_size=32, validation_split=0.2)
model_fcnn.save('fcnn.h5')

# Plot accuracy and loss for FCNN
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history_fcnn.history['accuracy'])
plt.plot(history_fcnn.history['val_accuracy'])
plt.title('FCNN Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.subplot(1, 2, 2)
plt.plot(history_fcnn.history['loss'])
plt.plot(history_fcnn.history['val_loss'])
plt.title('FCNN Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.tight_layout()
plt.show()

# Calculate accuracy for FCNN
y_pred_fcnn = model_fcnn.predict(X_test_reshaped)
y_pred_classes_fcnn = np.argmax(y_pred_fcnn, axis=1)
accuracy_fcnn = accuracy_score(y_test, y_pred_classes_fcnn)
print(f"FCNN Test Accuracy: {accuracy_fcnn}")

import matplotlib.pyplot as plt

# Assuming accuracies for Conv1D, LSTM, GRU, and FCNN are calculated
accuracies = [accuracy_cnn * 100, accuracy_gru * 100, accuracy_fcnn * 100]
models = ['Conv1D', 'GRU', 'FCNN']
colors = ['blue', 'red', 'green']

plt.bar(models, accuracies, color=colors)
plt.xlabel('Models')
plt.ylabel('Accuracy (%)')
plt.title('Model Accuracies')

for model, accuracy, color in zip(models, accuracies, colors):
    plt.text(model, accuracy, f'{accuracy:.2f}%', ha='center', va='bottom', color=color)

plt.ylim(0, 100)
plt.show()
